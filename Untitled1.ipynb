{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1050-1549.csv', '1550-1799.csv', '1800-1999.csv', '2000.csv', '2100.csv', '2150.csv', '2200.csv', '2300.csv', '2400.csv', '2450.csv', '2500.csv', '2600.csv', '2605.csv', '2610.csv', '2620.csv', '2625.csv', '2630.csv', '2635.csv', '2640.csv', '2650.csv', '2660.csv', '2665.csv', '2670.csv', '2680.csv', '2690.csv', '2700.csv', '2720.csv', '2730.csv', '2740.csv', '2750.csv', '2760.csv', '2765.csv', '2770.csv', '2791.csv', '2800.csv', '2820.csv', '2830.csv', '2840.csv', '2850.csv', '2860.csv', '2870.csv', '2880.csv', '2900.csv', '2920.csv', '2930.csv', '2942.csv', '2950.csv', '2960.csv', '2970.csv', '2980.csv', '2990.csv', '3000.csv', '3050.csv', '3060.csv', '3070.csv', '3080.csv', '3100.csv', '3120.csv', '3140.csv', '3150.csv', '3200.csv', '3210.csv', '3220.csv', '3230.csv', '3250.csv', '3300.csv', '3310.csv', '3320.csv', '3330.csv', '3360.csv', '3370.csv', '3390.csv', '3400.csv', '3450.csv', '3460.csv', '3480.csv', '3490.csv', '3500.csv', '3520.csv', '3540.csv', '3550.csv', '3600.csv', '3630.csv', '3650.csv', '3660.csv', '3670.csv', '3700.csv', '3720.csv', '3730.csv', '3740.csv', '3751.csv', '3760.csv', '3770.csv', '3782.csv', '3790.csv', '4000.csv', '4030.csv', '4040.csv', '4050.csv', '4060.csv', '4070.csv', '4100.csv', '4130.csv', '4140.csv', '4160.csv', '4171.csv', '4173.csv', '4174.csv', '4180.csv', '4190.csv', '4200.csv', '4220.csv', '4230.csv', '4241.csv', '4242.csv', '4243.csv', '4250.csv', '4261.csv', '4262.csv', '4270.csv', '4281.csv', '4291.csv', '4293.csv', '4295.csv', '4296.csv', '4300.csv', '4320.csv', '4330.csv', '4340.csv', '4350.csv', '4360.csv', '4370.csv', '4390.csv', '4400.csv', '4420.csv', '4440.csv', '4450.csv', '4460.csv', '4470.csv', '4480.csv', '4490.csv', '4500.csv', '4520.csv', '4532.csv', '4534.csv', '4540.csv', '4550.csv', '4560.csv', '4571.csv', '4572.csv', '4573.csv', '4581.csv', '4583.csv', '4591.csv', '4592.csv', '4593.csv', '4600.csv', '4621.csv', '4622.csv', '4623.csv', '4632.csv', '4640.csv', '4652.csv', '4653.csv', '4654.csv', '4660.csv', '4671.csv', '4672.csv', '4673.csv', '4681.csv', '4682.csv', '4683.csv', '4684.csv', '4690.csv', '4700.csv', '4720.csv', '4733.csv', '4735.csv', '4736.csv', '4750.csv', '4760.csv', '4771.csv', '4772.csv', '4773.csv', '4780.csv', '4791.csv', '4792.csv', '4793.csv', '4800.csv', '4840.csv', '4850.csv', '4862.csv', '4863.csv', '4871.csv', '4872.csv', '4873.csv', '4874.csv', '4880.csv', '4891.csv', '4892.csv', '4894.csv', '4895.csv', '4900.csv', '4912.csv', '4913.csv', '4920.csv', '4930.csv', '4941.csv', '4943.csv', '4944.csv', '4951.csv', '4952.csv', '4953.csv', '4960.csv', '4970.csv', '4983.csv', '4990.csv', '5000.csv', '5200.csv', '5210.csv', '5220.csv', '5230.csv', '5240.csv', '5250.csv', '5260.csv', '5270.csv', '5290.csv', '5300.csv', '5320.csv', '5330.csv', '5350.csv', '5370.csv', '5380.csv', '5390.csv', '5400.csv', '5450.csv', '5462.csv', '5463.csv', '5464.csv', '5466.csv', '5471.csv', '5474.csv', '5485.csv', '5491.csv', '5492.csv', '5500.csv', '5540.csv', '5550.csv', '5560.csv', '5580.csv', '5591.csv', '5592.csv', '5600.csv', '5610.csv', '5620.csv', '5631.csv', '5642.csv', '5672.csv', '5683.csv', '5690.csv', '5700.csv', '5750.csv', '5762.csv', '5771.csv', '5772.csv', '5792.csv', '5800.csv', '5853.csv', '5854.csv', '5856.csv', '5863.csv', '5871.csv', '5874.csv', '5881.csv', '5882.csv', '5883.csv', '5884.csv', '5892.csv', '5900.csv', '5932.csv', '5935.csv', '5953.csv', '5960.csv', '5970.csv', '5985.csv', '6000.csv', '6040.csv', '6051.csv', '6052.csv', '6064.csv', '6070.csv', '6091.csv', '6092.csv', '6093.csv', '6094.csv', '6100.csv', '6200.csv', '6230.csv', '6240.csv', '6261.csv', '6270.csv', '6280.csv', '6300.csv', '6310.csv', '6320.csv', '6330.csv', '6340.csv', '6360.csv', '6372.csv', '6392.csv', '6400.csv', '6430.csv', '6440.csv', '6470.csv', '6500.csv', '6510.csv', '6520.csv', '6534.csv', '6535.csv', '6541.csv', '6560.csv', '6580.csv', '6600.csv', '6621.csv', '6622.csv', '6623.csv', '6630.csv', '6640.csv', '6650.csv', '6660.csv', '6670.csv', '6682.csv', '6683.csv', '6690.csv', '6700.csv', '6705.csv', '6710.csv', '6715.csv', '6720.csv', '6731.csv', '6740.csv', '6752.csv', '6753.csv', '6760.csv', '6771.csv', '6780.csv', '6792.csv', '6800.csv', '6818.csv', '6823.csv', '6830.csv', '6840.csv', '6851.csv', '6852.csv', '6853.csv', '6854.csv', '6855.csv', '6857.csv', '6862.csv', '6870.csv', '6880.csv', '6893.csv', '6900.csv', '6920.csv', '6933.csv', '6940.csv', '6950.csv', '6960.csv', '6971.csv', '6973.csv', '6980.csv', '6990.csv', '7000.csv', '7080.csv', '7100.csv', '7120.csv', '7130.csv', '7140.csv', '7150.csv', '7160.csv', '7171.csv', '7173.csv', '7182.csv', '7183.csv', '7184.csv', '7190.csv', '7200.csv', '7250.csv', '7260.csv', '7270.csv', '7280.csv', '7300.csv', '7321.csv', '7323.csv', '7330.csv', '7361.csv', '7362.csv', '7400.csv', '7430.csv', '7441.csv', '7442.csv', '7451.csv', '7470.csv', '7480.csv', '7490.csv', '7500.csv', '7540.csv', '7550.csv', '7560.csv', '7570.csv', '7600.csv', '7620.csv', '7650.csv', '7660.csv', '7673.csv', '7680.csv', '7700.csv', '7730.csv', '7741.csv', '7742.csv', '7752.csv', '7755.csv', '7760.csv', '7770.csv', '7790.csv', '7800.csv', '7830.csv', '7840.csv', '7850.csv', '7860.csv', '7870.csv', '7884.csv', '7900.csv', '7950.csv', '7960.csv', '7970.csv', '7980.csv', '7990.csv', '8000.csv', '8200.csv', '8210.csv', '8220.csv', '8230.csv', '8240.csv', '8250.csv', '8260.csv', '8270.csv', '8300.csv', '8305.csv', '8310.csv', '8320.csv', '8330.csv', '8340.csv', '8350.csv', '8355.csv', '8361.csv', '8362.csv', '8370.csv', '8380.csv', '8381.csv', '8382.csv', '8400.csv', '8410.csv', '8420.csv', '8444.csv', '8450.csv', '8462.csv', '8464.csv', '8471.csv', '8472.csv', '8500.csv', '8520.csv', '8530.csv', '8541.csv', '8543.csv', '8544.csv', '8550.csv', '8560.csv', '8570.csv', '8581.csv', '8585.csv', '8586.csv', '8592.csv', '8600.csv', '8620.csv', '8632.csv', '8641.csv', '8643.csv', '8653.csv', '8654.csv', '8660.csv', '8670.csv', '8680.csv', '8700.csv', '8721.csv', '8722.csv', '8723.csv', '8732.csv', '8740.csv', '8751.csv', '8752.csv', '8762.csv', '8763.csv', '8765.csv', '8766.csv', '8781.csv', '8783.csv', '8800.csv', '8830.csv', '8831.csv', '8832.csv', '8840.csv', '8850.csv', '8860.csv', '8870.csv', '8881.csv', '8882.csv', '8883.csv', '8900.csv', '8920.csv', '8930.csv', '8940.csv', '8950.csv', '8960.csv', '8961.csv', '8963.csv', '8970.csv', '8981.csv', '8983.csv', '8990.csv', '9000.csv', '9200.csv', '9210.csv', '9220.csv', '9230.csv', '9240.csv', '9260.csv', '9270.csv', '9280.csv', '9293.csv', '9300.csv', '9310.csv', '9320.csv', '9330.csv', '9340.csv', '9352.csv', '9362.csv', '9370.csv', '9380.csv', '9381.csv', '9382.csv', '9400.csv', '9430.csv', '9440.csv', '9460.csv', '9480.csv', '9490.csv', '9492.csv', '9493.csv', '9500.csv', '9510.csv', '9520.csv', '9530.csv', '9541.csv', '9550.csv', '9560.csv', '9574.csv', '9575.csv', '9600.csv', '9610.csv', '9620.csv', '9631.csv', '9632.csv', '9640.csv', '9670.csv', '9681.csv', '9690.csv', '9700.csv', '9740.csv', '9750.csv', '9760.csv', '9800.csv', '9830.csv', '9850.csv', '9870.csv', '9881.csv', '9900.csv', '9940.csv', '9970.csv', '9981.csv', '9982.csv', '9990.csv']\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import requests\n",
    "import platform\n",
    "import statistics\n",
    "import bs4\n",
    "import re\n",
    "#import matplotlib\n",
    "#matplotlib.use('agg')\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "def download_txt(url, save_path='./downloaded'):\n",
    "    response = requests.get(url)\n",
    "    with open(save_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "def html_thead_to_list(table_head):\n",
    "    l = []\n",
    "    rows = table_head.find_all('tr')\n",
    "    for tr in rows:\n",
    "        lr = []\n",
    "        cols = tr.find_all('th')\n",
    "        for c in cols:\n",
    "            c = c.getText().strip()\n",
    "            #print(c)\n",
    "            lr.append(c)\n",
    "        l.append(lr)\n",
    "    return l\n",
    "\n",
    "def get_zip_code(str):\n",
    "    str = str.replace(' KÃ¸benhavn K','')\n",
    "    return str[-4:]\n",
    "\n",
    "def get_sell_date(s):\n",
    "    #print (s)\n",
    "    s = re.match('([\\d-]*)', s, 0)\n",
    "    s = s.group()\n",
    "   # print(s)\n",
    "    return s\n",
    "\n",
    "def html_tbody_to_list(table_body):\n",
    "    l = []\n",
    "    rows = table_body.find_all('tr')\n",
    "    for tr in rows:\n",
    "        lr = []\n",
    "        cols = tr.find_all('td')\n",
    "        for i,c in enumerate(cols):\n",
    "            c = c.getText().strip()\n",
    "            if (i == 0):\n",
    "                zipcode = get_zip_code(c)\n",
    "                lr.append(c)\n",
    "                lr.append(zipcode)\n",
    "            elif(i == 2):\n",
    "\n",
    "                sell_date = get_sell_date(c)\n",
    "                sell_type = c.replace(sell_date,'')\n",
    "                #5-05-2017Andet\n",
    "                #print(sell_date)\n",
    "                #print(sell_type)\n",
    "                lr.append(sell_date)\n",
    "                lr.append(sell_type)\n",
    "\n",
    "            else:\n",
    "                #print(c)\n",
    "                lr.append(c)\n",
    "        l.append(lr)\n",
    "    return l\n",
    "\n",
    "csv_files = []\n",
    "\n",
    "def html_file_to_csv(html_file):\n",
    "    base_url = 'http://138.197.184.35/boliga/'\n",
    "    url = base_url + html_file;\n",
    "    r = requests.get(url)\n",
    "    example_html = r.content.decode('utf-8')\n",
    "    #html_file\n",
    "    rows = html_to_csv_list(example_html)\n",
    "    #print(html_file)\n",
    "    \n",
    "    csv_file = get_csv_filename_from_html(html_file)\n",
    "    #print(csv_file)\n",
    "    if (not (csv_file in csv_files) ):\n",
    "        csv_files.append(csv_file)\n",
    "        \n",
    "    generate_csv(rows, csv_file)\n",
    "\n",
    "def get_csv_filename_from_html(z):\n",
    "    z = re.match('[\\d-]*', z, 0)\n",
    "    z = z.group()\n",
    "    z = z + '.csv'\n",
    "    return z\n",
    "\n",
    "def file_to_html(txt_path):\n",
    "    with open( txt_path ) as f:\n",
    "        example_html = f.read()\n",
    "    return example_html\n",
    "        #rows = html_to_csv_list(example_html)\n",
    "        #generate_csv(rows, csv_file)\n",
    "\n",
    "def html_to_csv_list(example_html):\n",
    "\n",
    "        data = []\n",
    "\n",
    "        soup = bs4.BeautifulSoup(example_html, 'html5lib')\n",
    "        table = soup.find('table')\n",
    "        #if(table.get('id') == 'searchresult'):\n",
    "            #table_head = table.find('thead')\n",
    "            #b_list = html_thead_to_list(table_head)\n",
    "        table_body = table.find('tbody')\n",
    "        a_list = html_tbody_to_list(table_body)\n",
    "            #b_list.extend(a_list)\n",
    "            #print(b_list)\n",
    "        data = a_list\n",
    "        return data\n",
    "\n",
    "\n",
    "def generate_csv(rows, csv_output_path):\n",
    "\n",
    "    if platform.system() == 'Windows':\n",
    "        newline=''\n",
    "    else:\n",
    "        newline=None\n",
    "    with open(csv_output_path, 'a', newline=newline, encoding='utf-8') as f:\n",
    "        output_writer = csv.writer(f)\n",
    "        for row in rows:\n",
    "            #if(if file exist the skipp the first row)\n",
    "            output_writer.writerow(row)\n",
    "\n",
    "def get_zipcsv_from_list(scraped_list):\n",
    "    row = ['address','zip_code','price','sell_date','sell_type','price_per_sq_m','no_rooms','housing_type','size_in_sq_m','year_of_construction',\n",
    "           'price_change_in_pct']\n",
    "\n",
    "    for z in scraped_list:\n",
    "        csv_file_name = get_csv_filename_from_html(z)\n",
    "        #print(csv_file_name)\n",
    "        csv_path = os.path.join(os.getcwd(), csv_file_name)\n",
    "        if platform.system() == 'Windows':\n",
    "            newline=''\n",
    "        else:\n",
    "            newline=None\n",
    "        with open(csv_path, 'w', newline=newline, encoding='utf-8') as f:\n",
    "            output_writer = csv.writer(f)\n",
    "                #if(if file exist the skipp the first row)\n",
    "            output_writer.writerow(row)\n",
    "\n",
    "def get_zipcodes(html_txt):\n",
    "        #response = requests.get(url)\n",
    "        #r = requests.get('http://138.197.184.35/boliga/')\n",
    "        #my_html = r.content.decode('utf-8')\n",
    "        soup = bs4.BeautifulSoup(html_txt, 'html5lib')\n",
    "        table = soup.find('table')\n",
    "        \n",
    "\n",
    "        table_body = table.find('tbody')\n",
    "\n",
    "        l = []\n",
    "        rows = table_body.find_all('tr')\n",
    "        rows.pop(0)\n",
    "        rows.pop(1)\n",
    "        rows.pop(2)\n",
    "        for tr in rows:\n",
    "            table_data = tr.find_all('td')\n",
    "        #    print (table_data)\n",
    "        #    break\n",
    "            for data in table_data:\n",
    "                last_td = data.find_all('a')\n",
    "                for a in last_td:\n",
    "                    c = a.getText().strip()\n",
    "                    \n",
    "                    l.append(c)\n",
    "\n",
    "        return l\n",
    "\n",
    "def loop_and_scrape(url_list):\n",
    "    for l in url_list:\n",
    "        html_file_to_csv(l)\n",
    "\n",
    "def run():\n",
    "    file_url = 'http://138.197.184.35/boliga' \n",
    "    txt_file_name = os.path.basename(file_url)\n",
    "    txt_path = os.path.join('./', txt_file_name)\n",
    "    txt_path = txt_path + '.html'\n",
    "    download_txt(file_url, txt_path)\n",
    "    html_txt = file_to_html(txt_path)\n",
    "    \n",
    "    ##index_url = 'http://138.197.184.35/boliga'\n",
    "    ##scraped_list= ['4500_130.html','1050-1549_1.html','1050-1549_36.html']\n",
    "    ##get_zipcsv_from_list(scraped_list)\n",
    "    \n",
    "    url_list= get_zipcodes(html_txt)\n",
    "    #print(url_list)\n",
    "\n",
    "    #url_list = ['1050-1549_1.html','1050-1549_3.html','1050-1549_4.html','1050-1549_5.html','1050-1549_6.html','1050-1549_7.html','1050-1549_8.html',\n",
    "    #      '1050-1549_9.html','1050-1549_10.html','1050-1549_11.html','1050-1549_12.html','1050-1549_13.html','1050-1549_14.html',\n",
    "    #      '1050-1549_15.html']\n",
    "    get_zipcsv_from_list(url_list)\n",
    "    loop_and_scrape(url_list)\n",
    "    print(csv_files)\n",
    "    print('done')\n",
    "    #\n",
    "    \n",
    "    #file_url = 'http://138.197.184.35/boliga/1050-1549_1.html'\n",
    "    #txt_file_name = os.path.basename(file_url)\n",
    "    #txt_path = os.path.join('./', txt_file_name)\n",
    "    #download_txt(file_url, txt_path)\n",
    "    #csv_file_name = 'something.csv'\n",
    "    #csv_path = os.path.join(os.getcwd(), csv_file_name)\n",
    "    #scrape_housing_data(txt_path)\n",
    "    #file_to_csv(txt_path, csv_path)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
